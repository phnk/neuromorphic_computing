# Seminar 2

## Discussion of paper
- None all problems are suitable for neuromorphic computing (like camera problems)
- Paper is very optimistic

## Lecture
[NI01 - Neural networks: a historical perspective](https://tube.switch.ch/switchcast/uzh.ch/events/a4902615-fd2f-4857-8492-49d92e542b79)

### Comments about lecture
- Emulate vs Simulate
- So is the brain continuous or discrete?
- pre vs postsynaptic (is this where we look at?)
- action potential (spikes)
- Hebbian learning (STDP)
- "Structure determines function"
	* We can't do this with logic gates because they all have the same structure
- Synapses produce some function and some dynamics (in biology)
- Memory potential (membrane potentials?)
- Hyperpolarized
- Synapses have linear properties and non-linear properties (EPSC and EPSP?)
- Different shapes of action potentials in the world
- Integrate and fire
- Excitation and inhibition
- Hodgkin-Huxley model
- Perceptron learning algorithm
- The mark 1 electronic system
- LSM learning algorithm
- SOM (self-organizing maps) learning algorithm
- The neocognitron
- Error backpropagation
- Hopfield networks (recurrent networks)
- Boltzmann Machines
- Attractor network
- Neuromorphic Engineering/Computing/Devices

## Homework
- Finish the video
	* Note down things that we don't understand
	* Start at 19:39
- Learning approaches 10-minute seminar
 Learning approaches 10 minute seminar
